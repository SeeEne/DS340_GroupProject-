{"cells":[{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10518,"status":"ok","timestamp":1681058586930,"user":{"displayName":"Xiaoyu Yang","userId":"15448855580442155408"},"user_tz":240},"id":"EBKlaZjBeMy_","outputId":"285ec665-faf0-4a5d-b34b-0bb3da1e1922"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","\n","# Load the decoder model\n","decoder = load_model('/content/drive/My Drive/2023_spring/DS340/DS340_GroupProject/decoder_model_Pikachu.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFNoQwyg1xOZ"},"outputs":[],"source":["import os\n","import cv2\n","from sklearn.model_selection import train_test_split\n","\n","def load_images(folder_path):\n","    image_list = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".jpg\"):\n","            # Read image\n","            img = cv2.imread(os.path.join(folder_path, filename))\n","            # Convert to one channel\n","            # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","            # Preform normalization and convert to np array\n","            img = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n","            img = img[:,:,::-1]\n","            img_array = np.array(img) / 255.0\n","            # Fallten image\n","            # img_array = img_array.flatten()\n","            image_list.append(img_array)\n","    return np.array(image_list)\n","\n","folder_path = \"/content/drive/My Drive/2023_spring/DS340/DS340_GroupProject/data/Pikachu\"\n","x_data = load_images(folder_path)\n","\n","x_train, x_val = train_test_split(x_data, test_size=0.1, random_state=42)\n","\n","x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_lxFasPzdpf"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","dataset = tf.data.Dataset.from_tensor_slices(x_data)\n","\n","# Set the batch size\n","BATCH_SIZE = 128\n","dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkJUU8EkkCTF"},"outputs":[],"source":["def denormalize(image):\n","    return image\n","\n","def display_image(image):\n","    denorm_image = denormalize(image)\n","    plt.imshow(denorm_image)\n","    plt.axis('off')\n","    plt.show()\n","\n","def display_batch(images, title):\n","    fig = plt.figure(figsize=(6, 6))\n","    plt.suptitle(title)\n","\n","    for i in range(9):\n","        plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i])\n","        plt.axis('off')\n","    \n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWf8rY8dpTcf"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model, Sequential\n","from tensorflow.keras.layers import InputLayer, Lambda, Dense, Flatten,LeakyReLU,Conv2D,Activation\n","\n","\n","LATENT_DIM = 256\n","NOISE_DIM = 100\n","IMAGE_SIZE = 128\n","\n","def sampling(args):\n","    z_mean, z_log_var = args\n","    batch_size = tf.shape(z_mean)[0]\n","    epsilon = tf.keras.backend.random_normal(shape=(batch_size, LATENT_DIM))\n","    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","\n","def generator(decoder, noise_dim=NOISE_DIM):\n","    \"\"\"\n","    Generate image from noise \n","    Inputs:\n","    - decoder: pretrain model for genrate image freom mean and std\n","    - noise_dim: the dimension of the noise \n","    \n","    Returns:\n","    TensorFlow Tensor with shape [number of image in one batch, 128, 128, 3]\n","    \"\"\"\n","\n","    # Freeze layers in the saved model\n","    for i, layer in enumerate(decoder.layers):\n","\n","        # Check if it's not the last layer\n","        if i != len(decoder.layers) - 2:\n","          layer.trainable = False\n","        else:\n","          layer.trainable = True\n","        \n","        layer._name = f'saved_model_{i}_{layer.name}'\n","\n","\n","    model = Sequential([\n","        tf.keras.Input(shape=noise_dim),\n","        tf.keras.layers.Reshape((noise_dim, 1)),\n","        tf.keras.layers.Conv1D(32, 3, activation = LeakyReLU()),\n","        tf.keras.layers.Conv1D(64, 3, activation=LeakyReLU()),\n","        tf.keras.layers.Conv1D(128, 3, activation=LeakyReLU()),\n","        tf.keras.layers.MaxPooling1D(pool_size=2, strides=1, padding='valid'),\n","        tf.keras.layers.Dropout(0.25),\n","        Flatten(),\n","        Dense(256, input_dim=noise_dim, activation=LeakyReLU()),\n","        Dense(512, activation=LeakyReLU()),\n","        Dense(512, activation=LeakyReLU()),\n","        Lambda(lambda x: sampling([x[:, :256], x[:, 256:]]))\n","    ])\n","    \n","    # Add layers from the saved model\n","    for layer in decoder.layers:\n","        model.add(layer)\n","\n","    model.add(Activation('tanh'))\n","\n","    return model\n","\n","generator_model = generator(decoder)\n","noise_example = np.random.rand(2, NOISE_DIM) # suppose 2 images in one batch\n","output_fake = generator_model(noise_example) # (2,49152) tensor\n","\n","# Let's check the image\n","output_reshape = output_fake.numpy()#.reshape(-1,128,128,3)\n","display_image(output_reshape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOJa_RVYvQgM"},"outputs":[],"source":["generator_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4GzTekznnuV"},"outputs":[],"source":["def discriminator(input_shape=(128,128,3)):\n","  \n","    \"\"\"Compute discriminator score for a batch of input images.\n","      \n","    Inputs:\n","    - x: tensor, shape [number of images in one batch, 128, 128, 3]\n","    \n","    Returns:\n","    TensorFlow Tensor with shape [number of images in one batch, 1], containing the score \n","    for an image being real for each input image.\n","    \"\"\"\n","\n","    model = tf.keras.Sequential()\n","    #model.add(tf.keras.layers.Reshape((IMAGE_SIZE,IMAGE_SIZE,3), input_shape = input_shape))\n","    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same',input_shape = input_shape))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","\n","    model.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","\n","    model.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","\n","    model.add(tf.keras.layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(64))\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","\n","    return model\n","\n","discriminator_model = discriminator()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GO6nTJZovDyN"},"outputs":[],"source":["discriminator_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdVNrjCFicK-"},"outputs":[],"source":["# construct discriminator loss\n","def generator_loss(fake_score):\n","    \"\"\"\n","    Input:\n","    fake_score is the result from discriminator, which is a [number of images in one batch, 1] tensor\n","\n","    Returns:\n","    output the distance between fake_score and all 1 [number of images in one batch, 1] tensor by using BinaryCrossentropy\n","    output is a 1 D tensor which contain the average batch loss value. Since we use reduction = 'sum_over_batch_size'\n","    \"\"\"\n","    # We need our generator loss as close as possible to 1, since 1 represent we fool the discrimiator.\n","    target = tf.ones_like(fake_score) # Tensor that contan batch_size number of 1. \n","    loss = tf.keras.losses.BinaryCrossentropy(reduction='auto')(target,fake_score)\n","    return loss\n","\n","\n","def disciminator_loss(fake_score,real_score):\n","    \"\"\"\n","    Input\n","    fake_score is the result from discriminator by judging the fake image, which is a batch_size * 1 tensor\n","    real_score is the result from discriminator by judging the real image, which is a batch_size * 1 tensor\n","\n","    Returns:\n","    the distance between fake_score and all 0 [number of images in one batch, 1] tebsor by using BinaryCrossentropy\n","    +  the distance between real_score and all 1 [number of images in one batch, 1] tensor by using BinaryCrossentropy\n","    =  1 D tensor which contain the average batch loss value. Since we use reduction = 'sum_over_batch_size'\n","    \"\"\"\n","    target_real = tf.ones_like(real_score)\n","    loss_real = tf.keras.losses.BinaryCrossentropy(reduction='auto')(target_real,real_score)\n","\n","    target_fake = tf.zeros_like(fake_score)\n","    loss_fake = tf.keras.losses.BinaryCrossentropy(reduction='auto')(target_fake,fake_score)\n","\n","    return loss_real + loss_fake\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1L2XBaH_h-8ECmrYZbZEI04NdKYttkfA3"},"id":"xX4C8rx1mxgW","outputId":"4ba42a71-9ea9-4924-921e-b75125ec16c6"},"outputs":[],"source":["@tf.function\n","def train_step(real_images,generator_model,discriminator_model,generator_optimizor,discriminator_optimizor):\n","    \"\"\"\n","    Input\n","    real_images: All images in one batch\n","    generator_model: generator model, we declear outside generator = generator()\n","    discriminator_model: discriminator model, we declear outside discriminator = discriminator()\n","    generator_optimizor: generator_optimizor for generator\n","    discriminator_optimizor: discriminator_optimizor for discriminator\n","\n","    Returns:\n","    the distance between fake_score and all 0 [number of images in one batch, 1] tebsor by using BinaryCrossentropy\n","    +  the distance between real_score and all 1 [number of images in one batch, 1] tensor by using BinaryCrossentropy\n","    =  1 D tensor which contain the average batch loss value. Since we use reduction = 'sum_over_batch_size'\n","    \"\"\"\n","    # real_images.shape[0] represent the number of images in one batch\n","    noise = tf.random.normal([real_images.shape[0], NOISE_DIM])\n","\n","    # Observe from tensorflow document\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n","\n","      # generate images: [number of images in one batch, 49152 = 128 * 128 * 3] tensor\n","      fake_images = generator_model(noise, training=True)\n","\n","      # Reshape images\n","      # fake_images = tf.reshape(fake_images,(-1,128,128,3))\n","      # real_images = tf.reshape(real_images,(-1,128,128,3))\n","\n","      # calculate the score of fake_images and real_images: [number of images in one batch, 1] tensor\n","      fake_score = discriminator_model(fake_images, training=True)\n","      real_score = discriminator_model(real_images, training=True)\n","\n","      # calculate the loss\n","      generator_loss_value = generator_loss(fake_score)\n","      # print(generator_loss_value)\n","      disciminator_loss_value = disciminator_loss(fake_score,real_score)\n","    \n","    # Update the weights of the model to minimize the loss value.\n","    generator_gradients = gen_tape.gradient(generator_loss_value, generator_model.trainable_weights)\n","    disciminator_gradients = dis_tape.gradient(disciminator_loss_value, discriminator_model.trainable_weights)\n","\n","    generator_optimizor.apply_gradients(zip(generator_gradients, generator_model.trainable_weights))\n","    discriminator_optimizor.apply_gradients(zip(disciminator_gradients, discriminator_model.trainable_weights))\n","\n","    return generator_loss_value,disciminator_loss_value,fake_images,fake_score,real_score\n","\n","\n","def train_gan(dataset, generator, discriminator, epochs):\n","    generator_optimizer = tf.keras.optimizers.Adam(2e-5)\n","    discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)\n","\n","    for epoch in range(epochs):\n","        gen_loss_sum = 0\n","        disc_loss_sum = 0\n","        num_batches = 0\n","        fake_score_sum = 0\n","        real_score_sum = 0\n","\n","        for image_batch in dataset:\n","            gen_loss, disc_loss,fake_images,fake_score,real_score = train_step(image_batch, generator, discriminator, generator_optimizer, discriminator_optimizer)\n","            gen_loss_sum += gen_loss\n","            disc_loss_sum += disc_loss\n","            num_batches += 1\n","            fake_score_sum += np.mean(fake_score.numpy())\n","            real_score_sum += np.mean(real_score.numpy())\n","\n","        if epoch % 5 == 0:\n","          generated_images = fake_images.numpy()[0:9]\n","          denorm_images = [denormalize(img) for img in generated_images]\n","          display_batch(denorm_images, f\"Generated images at epoch {epoch + 1}\")\n","\n","        \n","        print(f'Epoch {epoch+1}, Generator Loss: {gen_loss_sum/num_batches}, fake score: {fake_score_sum/num_batches}, Discriminator Loss: {disc_loss_sum/num_batches}, real score: {real_score_sum/num_batches}')\n","\n","generator_model = generator(decoder)\n","discriminator_model = discriminator()\n","train_gan(dataset, generator_model, discriminator_model, epochs=200)"]},{"cell_type":"markdown","metadata":{"id":"bMic1Ns31bvF"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO5KD4Y9kIpVgNuSfBqNUp2","name":"","version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}